# Phase 4 LSTM Normalization Fix - Step-by-Step Instructions

**Time Required:** 35 minutes total
**Expected Improvement:** RÂ² from 0.019 â†’ 0.3-0.6 (16-30Ã— better)

---

## Step 1: Apply the Normalization Fix (5 minutes)

### Open Your Notebook

1. Open `Phase_4_LSTM_Operational_Layer.ipynb` in Google Colab
2. Navigate to **Section 2, Cell 5** (the cell with `create_operational_features()` function)

### Replace the Function

Find this function:

```python
def create_operational_features(df):
    """
    Create enhanced operational features for LSTM
    """
    df = df.copy()

    # Request rate (invocations per minute)
    df['request_rate'] = df['invocation_rate'].fillna(0.0)  # âŒ PROBLEM: UNBOUNDED

    # Memory utilization (normalized)
    df['memory_util'] = (df['memory_mb'] / 3008.0).fillna(0.5)  # âœ“ OK

    # CPU proxy (duration-based estimation)
    df['cpu_util'] = (df['duration'] / 1000.0).clip(0, 1).fillna(0.5)  # âœ“ OK

    # Queue depth proxy (based on latency)
    df['queue_depth'] = (df['total_latency_ms'] / 1000.0).clip(0, 10).fillna(0.0)  # âŒ PROBLEM: SEMI-BOUNDED

    # Temporal encoding (cyclical)
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24.0)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24.0)

    # Select final features
    lstm_features = ['request_rate', 'memory_util', 'cpu_util', 'queue_depth', 'hour_sin']

    return df[lstm_features].values
```

**Replace with this FIXED version:**

```python
def create_operational_features(df):
    """
    Create enhanced operational features for LSTM with PROPER NORMALIZATION

    FIXED: All features now normalized to [0, 1] range for balanced learning
    """
    df = df.copy()

    # Request rate - NORMALIZE using log scale âœ“ FIXED
    # Log-scale normalization handles heavy-tailed distribution
    raw_request_rate = df['invocation_rate'].fillna(0.0)
    max_rate = raw_request_rate.max()
    df['request_rate'] = np.log1p(raw_request_rate) / np.log1p(max_rate + 1e-8)

    # Memory utilization (already normalized) âœ“ OK
    df['memory_util'] = (df['memory_mb'] / 3008.0).fillna(0.5)

    # CPU proxy (already normalized) âœ“ OK
    df['cpu_util'] = (df['duration'] / 1000.0).clip(0, 1).fillna(0.5)

    # Queue depth - NORMALIZE to [0,1] âœ“ FIXED
    # Min-max normalization to match other feature scales
    raw_queue = (df['total_latency_ms'] / 1000.0).fillna(0.0)
    max_queue = raw_queue.max()
    df['queue_depth'] = (raw_queue / (max_queue + 1e-8)).clip(0, 1)

    # Temporal encoding (cyclical) âœ“ OK
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24.0)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24.0)

    # Select final features
    lstm_features = ['request_rate', 'memory_util', 'cpu_util', 'queue_depth', 'hour_sin']

    return df[lstm_features].values
```

### What Changed?

**Line 1 - Request Rate (CRITICAL FIX):**
```python
# OLD (unbounded [0, 150+]):
df['request_rate'] = df['invocation_rate'].fillna(0.0)

# NEW (normalized [0, 1]):
raw_request_rate = df['invocation_rate'].fillna(0.0)
max_rate = raw_request_rate.max()
df['request_rate'] = np.log1p(raw_request_rate) / np.log1p(max_rate + 1e-8)
```

**Line 2 - Queue Depth (CRITICAL FIX):**
```python
# OLD (semi-bounded [0, 10]):
df['queue_depth'] = (df['total_latency_ms'] / 1000.0).clip(0, 10).fillna(0.0)

# NEW (normalized [0, 1]):
raw_queue = (df['total_latency_ms'] / 1000.0).fillna(0.0)
max_queue = raw_queue.max()
df['queue_depth'] = (raw_queue / (max_queue + 1e-8)).clip(0, 1)
```

**Why This Fixes the Problem:**
- Before: `request_rate` errors (50Â²=2500) dominated `memory_util` errors (0.2Â²=0.04) by 62,500Ã—
- After: All features in [0, 1] range with comparable variance (~0.04-0.10)
- LSTM will now learn from ALL features equally

---

## Step 2: Retrain the LSTM (20 minutes)

### Run These Sections in Order:

1. **Section 1: Load Data** (2 minutes)
   - Run all cells
   - Verify data loaded successfully

2. **Section 2: Feature Engineering** (1 minute)
   - Run the FIXED `create_operational_features()` cell
   - Check feature statistics output:
     - All means should be in [0, 0.5] range
     - All stds should be in [0.1, 0.3] range
   - âœ“ If values look reasonable, normalization is working

3. **Section 3: Dataset Creation** (1 minute)
   - Run all cells
   - Verify sequence counts (train: ~1.26M, val: ~271K, test: ~271K)

4. **Sections 4-5: Model Architecture** (30 seconds)
   - Run cells to define LSTM and loss function
   - These don't change, just definitions

5. **Section 6: LSTM Training** (15-18 minutes) â°
   - Run the training cell
   - **This is the main training loop - watch for:**
     - Training should take 15-20 minutes on GPU
     - Loss should decrease steadily
     - Early stopping might trigger around epoch 15-20
   - Model saves automatically to your Drive

**Expected Training Behavior:**
```
Epoch  1 | Train Loss: 0.08-0.12 | Val Loss: 0.09-0.13
Epoch  5 | Train Loss: 0.04-0.07 | Val Loss: 0.05-0.08
Epoch 10 | Train Loss: 0.03-0.05 | Val Loss: 0.04-0.06
Epoch 15 | Train Loss: 0.02-0.04 | Val Loss: 0.03-0.05
...
âœ“ New best model saved! (Val loss: ~0.03-0.05)
```

**Red Flags (if you see these, something's wrong):**
- âŒ Loss > 1.0 after epoch 5
- âŒ Loss increasing instead of decreasing
- âŒ NaN or Inf values
- âŒ Loss stuck at same value

6. **Section 7: Training Visualization** (30 seconds)
   - Run to see training curves
   - Should show smooth decreasing trend

---

## Step 3: Evaluate and Verify Results (2 minutes)

### Run Section 8: Model Evaluation

This section compares LSTM to baselines. After the fix, you should see:

**Expected Results:**

| Model | RMSE | MAE | RÂ² | Status |
|-------|------|-----|-----|--------|
| **LSTM** | **0.05-0.15** | **0.03-0.10** | **0.3-0.6** | âœ… **BEST** |
| Reactive | 0.270 | 0.104 | 0.047 | ðŸŸ¡ Baseline |
| Static 2Ã— | 0.485 | 0.222 | -2.182 | ðŸ”´ Poor |
| Moving Avg | 0.230 | 0.101 | 0.343 | ðŸŸ¢ Good |

**Critical Success Criteria:**
- âœ… **LSTM RÂ² > 0.3** (should be 0.3-0.6)
- âœ… **LSTM RÂ² > Moving Average RÂ² (0.343)**
- âœ… **LSTM RMSE < 0.15** (normalized scale)
- âœ… **LSTM RMSE < Moving Average RMSE (0.230)**

**Improvement Metrics:**
```
LSTM vs Reactive:          RMSE: -70 to -80%    RÂ²: +500 to +1100%
LSTM vs Moving Avg:        RMSE: -30 to -50%    RÂ²: +0 to +75%
```

**If RÂ² is still < 0.3:**
- Check feature statistics in Section 2 output
- Verify all features are in [0, 1] range
- May need to restart runtime and re-run from Section 1

---

## Step 4: Run Remaining Sections (2 minutes)

### Complete the Analysis

1. **Section 9: Prediction Visualization** (1 minute)
   - Run to see time series and scatter plots
   - Should show LSTM predictions closely following actual values

2. **Sections 10-11: Framework Evaluation** (1 minute)
   - Run the hierarchical framework simulation
   - Note: This is still simulated, but you can update with real LSTM performance later

3. **Section 12: Summary** (30 seconds)
   - Run to see final summary
   - Verify all achievements listed

---

## Step 5: Save and Document Results (5 minutes)

### Download the Notebook

1. In Colab: **File â†’ Download â†’ Download .ipynb**
2. Save as `Phase_4_LSTM_Operational_Layer_FIXED.ipynb`
3. Upload to your repository (replace old version OR keep both)

### Record Your Results

Create a file `PHASE_4_FIXED_RESULTS.txt` with:

```
Phase 4 LSTM - FIXED Results (After Normalization)

Training:
- Epochs completed: [INSERT NUMBER]
- Best validation loss: [INSERT VALUE from Section 6 output]
- Training time: [INSERT TIME in minutes]

Evaluation (Section 8):
- LSTM RMSE: [INSERT VALUE]
- LSTM MAE: [INSERT VALUE]
- LSTM RÂ²: [INSERT VALUE]
- Moving Average RÂ²: 0.343
- LSTM beats Moving Average: [YES/NO]

Success Criteria:
- âœ“ RÂ² > 0.3: [YES/NO]
- âœ“ RÂ² > Moving Average: [YES/NO]
- âœ“ RMSE < 0.15: [YES/NO]

Status: [READY FOR DEPLOYMENT / NEEDS INVESTIGATION]

Notes:
[Any observations about training or results]
```

### Backup Your Model

The model is automatically saved to:
```
/content/drive/MyDrive/mythesis/rohit-thesis/models/lstm_operational/best_lstm_predictor.pt
```

**Verify the file exists:**
1. Check your Google Drive
2. File size should be ~500KB-1MB
3. Timestamp should match your training time

---

## Troubleshooting

### Issue: RÂ² Still Low (< 0.3)

**Diagnosis:**
1. Check feature statistics in Section 2 output
2. Look at `Mean:` and `Std:` values

**Expected (after fix):**
```
Mean: [0.05-0.3, 0.4-0.6, 0.3-0.5, 0.1-0.3, -0.1-0.1]
Std:  [0.1-0.2, 0.2-0.3, 0.2-0.3, 0.1-0.2, 0.5-0.7]
```

**If request_rate mean > 10 or std > 50:**
- Fix didn't apply correctly
- Re-check the function replacement
- Restart runtime and re-run from Section 1

### Issue: Training Loss Not Decreasing

**Possible Causes:**
1. Learning rate too high/low
2. Gradient explosion (should be clipped)
3. Data quality issues

**Solution:**
- Check if loss is NaN or Inf
- Verify gradient clipping is enabled (max_norm=1.0)
- Try reducing learning rate to 5e-4 if loss oscillates

### Issue: OOM (Out of Memory) Error

**Solution:**
- Reduce batch size from 128 to 64 or 32
- Check GPU is enabled: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU

---

## After Successful Fix

### Update Your Documentation

Once you confirm RÂ² > 0.3 and LSTM beats Moving Average:

1. **Update Status:**
   - Phase 4: âœ… VALIDATED
   - LSTM RÂ²: [YOUR VALUE]
   - Status: READY FOR DEPLOYMENT

2. **Model Inventory:**
   - âœ… DQN Strategic: best_enhanced_dqn.pt (in repo)
   - âœ… PPO Tactical: best_ppo_tactical.pt (in backup)
   - âœ… LSTM Operational: best_lstm_predictor.pt (FIXED - in backup)

3. **Deployment Readiness:** 100% READY
   - All 3 layers validated
   - All models available
   - Complete hierarchical framework

### Proceed to New Thread

Use this message to start your deployment thread:

```
Phase 4 LSTM FIX COMPLETE âœ“

Updated Results:
- LSTM RÂ²: [INSERT YOUR VALUE] (was 0.019)
- LSTM beats Moving Average: YES
- Improvement: [INSERT %] better than before
- Status: VALIDATED and READY

All Three Layers Now Validated:
âœ“ Phase 2 DQN: Stable convergence
âœ“ Phase 3 PPO: 0.9036 validation reward (outstanding)
âœ“ Phase 4 LSTM: RÂ² [YOUR VALUE] (fixed and validated)

Complete hierarchical framework ready for deployment.

Please read:
- DEPLOYMENT_READINESS_ASSESSMENT.md (deployment architecture)
- NEW_THREAD_CONTINUATION_GUIDE.md (continuation instructions)

Request: Help me package the complete DQN + PPO + LSTM framework for
deployment. Timeline: 2 weeks to Docker deployment for thesis demo.
```

---

## Summary

**Total Time:** ~35 minutes
- 5 min: Apply fix
- 20 min: Retrain
- 2 min: Verify
- 5 min: Save and document
- 3 min: Buffer

**Expected Outcome:**
- RÂ²: 0.3-0.6 (16-30Ã— improvement)
- LSTM outperforms all baselines
- Complete 3-layer framework validated
- Ready for deployment

**Next Step:** Run the fix in Colab, then start your new thread for deployment!

---

**Good luck with the fix! This will complete your hierarchical framework beautifully.** ðŸš€
